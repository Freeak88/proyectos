# üß† Ollama Local + Lexicon ‚Äî Gu√≠a Operativa

> Lecciones aprendidas y mejores pr√°cticas para usar Ollama (Qwen3:8b) como motor de generaci√≥n de contenido Lexicon.
> **Fecha de documentaci√≥n:** 14/02/2026
> **Basado en:** Prueba real con art√≠culo "WiFi Marketing para embudo.com.ar"

---

## ‚ö†Ô∏è Hallazgo Cr√≠tico

**Qwen3:8b (local via Ollama) NO puede generar art√≠culos completos de 1,200+ palabras en un solo prompt.**

El modelo se "ahoga" (timeout, procesos colgados, output incompleto) cuando se le pide contenido extenso en una sola llamada.

---

## ‚úÖ Soluci√≥n Validada: Chunked Generation

**Principio:** Dividir el art√≠culo en chunks de ~300-400 palabras y generar cada uno por separado.

### Estructura de chunks para art√≠culo tipo:

| Chunk # | Contenido | Palabras estimadas |
|---------|-----------|-------------------|
| 1 | Snippet Zero + Introducci√≥n | ~200 |
| 2 | Secciones 1-2 (ej: Restaurantes + Hoteles) | ~300 |
| 3 | Secciones 3-4 (ej: Retail + Est√©tica) | ~300 |
| 4 | Conclusi√≥n + CTA + Links | ~150 |
| **TOTAL** | | **~950-1,200** |

---

## üîÑ Flujo de Trabajo Optimizado

### Para Pilar Pages (~1,800-2,500 palabras):

```
Chunk 1: Snippet Zero + Intro (~200 palabras)
Chunk 2: ¬øC√≥mo funciona? (~300 palabras)
Chunk 3: Beneficios (~400 palabras)
Chunk 4: Casos por industria (~400 palabras)
Chunk 5: Comparativa/Tabla (~300 palabras)
Chunk 6: Implementaci√≥n (~300 palabras)
Chunk 7: FAQ (~200 palabras)
Chunk 8: Conclusi√≥n (~150 palabras)
```

**Tiempo total:** ~10-12 minutos (vs timeout con generaci√≥n √∫nica)

### Para Sat√©lites (~1,000-1,500 palabras):

```
Chunk 1: Snippet Zero + Intro (~200 palabras)
Chunk 2: Contenido principal A (~300 palabras)
Chunk 3: Contenido principal B (~300 palabras)
Chunk 4: Conclusi√≥n + CTA + Link al pilar (~150 palabras)
```

**Tiempo total:** ~5-6 minutos

---

## üìù Prompt Template para Chunks

### Chunk 1 (Introducci√≥n):
```
Escrib√≠ la INTRODUCCI√ìN de un art√≠culo SEO sobre "[TEMA]" (~200 palabras).

REQUISITOS:
1. Snippet Zero Answer Box: definici√≥n breve de [CONCEPTO]
2. Contexto: por qu√© es importante
3. Mencionar que el art√≠culo cubrir√° [X, Y, Z]
4. Transici√≥n a la primera secci√≥n
5. Link al pilar con anchor "[KEYWORD PRINCIPAL]"
6. Tono: [profesional/accesible/t√©cnico]

Respond√© SOLO el HTML.
```

### Chunks 2-N (Contenido):
```
Escrib√≠ dos secciones de un art√≠culo sobre [TEMA] (~300 palabras total).

SECCI√ìN 1 - [SUBTEMA A]:
- Problema: [descripci√≥n]
- Soluci√≥n: [soluci√≥n WiFimarketing]
- Resultado: [m√©trica estimada]

SECCI√ìN 2 - [SUBTEMA B]:
- Problema: [descripci√≥n]
- Soluci√≥n: [soluci√≥n]
- Resultado: [m√©trica estimada]

REQUISITOS:
- Usar <h3> para cada secci√≥n
- Tono pr√°ctico con datos estimados
- Entidades: [lista de entidades LSI]

Respond√© SOLO el HTML.
```

### Chunk Final (Conclusi√≥n):
```
Escrib√≠ la CONCLUSI√ìN de un art√≠culo "[T√çTULO]" (~150 palabras).

REQUISITOS:
1. Resumir brevemente los puntos clave
2. Mensaje motivador sobre [TEMA]
3. CTA: invitar a leer [PR√ìXIMO CONTENIDO]
4. Link al pilar con anchor "[KEYWORD]"
5. Tono motivador pero profesional

Respond√© SOLO el HTML.
```

---

## üéØ Ajustes a Skills de Lexicon

### Modificaciones necesarias a los prompts originales:

| Skill | Ajuste requerido |
|-------|------------------|
| `lexicon-article-writer` | Cambiar "Escrib√≠ un art√≠culo de X palabras" ‚Üí "Escrib√≠ la INTRODUCCI√ìN...", "Escrib√≠ la secci√≥n..." |
| `lexicon-ghostwriter` | Aplicar adversarial editing POR CHUNK, no al art√≠culo completo |
| `lexicon-psycho-llm` | Generar Shadow Twin y Abstract del art√≠culo COMPLETO ya ensamblado |

---

## üìä M√©tricas Reales (Qwen3:8b en RX 6700 XT)

| Tipo de generaci√≥n | Tiempo por chunk | √âxito |
|-------------------|------------------|-------|
| Chunk 300 palabras | 30-45 segundos | ‚úÖ 100% |
| Chunk 400 palabras | 45-60 segundos | ‚úÖ 100% |
| Art√≠culo 1,200 palabras (√∫nico) | 3-5 minutos | ‚ùå 30% (timeouts) |
| Art√≠culo 2,000 palabras (√∫nico) | 5-8 minutos | ‚ùå 0% (siempre falla) |

**Conclusi√≥n:** Chunks de 300-400 palabras = sweet spot.

---

## üí∞ Costos

| Componente | Costo por art√≠culo |
|------------|-------------------|
| DataForSEO (research) | $0.05-0.10 |
| Ollama (generaci√≥n chunks) | $0.00 |
| **Total** | **~$0.05-0.10** |

**Comparaci√≥n:** GPT-4o-mini para art√≠culo completo = ~$0.30-0.50

**Ahorro:** 70-80%

---

## üõ†Ô∏è Scripts √ötiles

### Ensamblar chunks autom√°ticamente:
```bash
#!/bin/bash
# assemble-article.sh

cat chunk-1-intro.html \
    chunk-2-seccion.html \
    chunk-3-seccion.html \
    chunk-4-conclusion.html > articulo-completo.html

echo "Art√≠culo ensamblado: $(wc -w < articulo-completo.html) palabras"
```

---

## ‚ö° Troubleshooting

### Problema: Chunk tarda m√°s de 90 segundos
**Soluci√≥n:** Reducir a 250 palabras o simplificar prompt.

### Problema: Output cortado/incompleto
**Soluci√≥n:** El chunk es muy largo. Dividir en 2 chunks m√°s peque√±os.

### Problema: Repetici√≥n entre chunks
**Soluci√≥n:** Asegurar que cada chunk tenga transici√≥n clara y no solape contenido.

---

## üìö Flujo Completo Documentado

### Para nuevo art√≠culo:

1. **Research** (DataForSEO API)
   - Keywords, volumen, competencia
   - Top 3 URLs para an√°lisis

2. **Strategy** (Ollama - 1 prompt)
   - Definir pilar vs sat√©lites
   - Asignar TOFU/MOFU/BOFU
   - Validar semanticamente

3. **Writing** (Ollama - N chunks)
   - Chunk 1: Intro + Snippet Zero
   - Chunks 2-N: Contenido por secciones
   - Chunk Final: Conclusi√≥n + CTA

4. **Ensamblaje** (script/manual)
   - Concatenar chunks
   - Verificar coherencia
   - Contar palabras totales

5. **Ghostwriter** (Ollama - por chunk o completo)
   - Aplicar burstiness
   - Aplicar perplexity
   - Eliminar frases prohibidas

6. **Psycho-LLM** (Ollama - 1 prompt)
   - Generar Abstract (Shadow Twin)
   - Agregar citas [1], [2]
   - LaTeX para n√∫meros

7. **Publicaci√≥n**
   - Art√≠culo humano (Ghostwriter)
   - /llms.txt (Shadow Twin)
   - Interlinking a sat√©lites/pilar

---

## üîó Referencias

- **Qwen3:8b** ejecut√°ndose en: `whitemonkey` (100.73.185.25:11434)
- **GPU:** RX 6700 XT (12GB VRAM)
- **Skill Lexicon:** `lexicon-article-writer`, `lexicon-ghostwriter`, `lexicon-psycho-llm`
- **Prueba de concepto:** `/projects/lexicon/wifi-marketing-*/`

---

*Documentaci√≥n creada tras prueba real. Actualizar si se cambia de modelo (ej: gemma3:12b) o si se ajustan los l√≠mites de chunks.*
